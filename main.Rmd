---
title: "Effects of Aim Training Performance, Lifestyle Habits, and Environmental Factors on Fatigue and Stress"
author:
    - Ian Chen^[Review of early drafts of the report was given by Yan Yi Lance Du]
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
    bookdown::pdf_document2:
        toc: false
        latex_engine: xelatex
---

# Abstract

**Purpose**:
In this study, we investigated the effects of lifestyle, environment, and response time on students mental state.

**Methods**:
Participants were 145 students from an introductory statistics class at the University of Illinois, Urbana Champaign.
Participants played an aim training game and completed a post-game survey that assessed personal and environmental factors that might affect aim training performance (i.e., reaction time).
We operationalized mental state as students' stress and fatigue levels. 

**Results**:
We found that an increase in response time is associated with larger stress levels.
Moreover, a distractive environment led to increased stress, but is counteracted by being active in sports.
The only predictors associated with decreased fatigue is getting enough sleep and exercise.
We also verified that aggregating the predictors led to an improved model.

**Implications**:
Students tend to face high levels of stress and fatigue in academic settings.
Our study implies that different interventions may be required for students to mitigate the negative effects of stress on performance.
Indeed, future studies should consider all not only response times, but also lifestyle, environmental factors before proposing remedies for Fatigue and Stress.

# Introduction

In this study, we explore which indicators are significantly correlated with reaction time, a proxy for their performance.
We study both self reported fatigue and stress levels, as well as their lifestyle habits and environment.

## Research Questions

Here, we have three primary research questions (RQ):

1. Does aim training performance correlate to impaired mental state?
2. Are there environmental factors consistent with impared mental state?
3. Are there lifestyle factors consistent with impared mental state?

We hypothesize that worse performance on aim trainers would lead to more fatigue and stress levels.
We expect poor environments to affect both stress and fatigue equally.
We think that a poor lifestyle would lead to increased fatigue, and may not affect stress.

# Materials and Methods

We collect our dataset from introductory statistics students at the University of Illinois, Urbana Champaign.
An online survey was posted that all students needed to fill in, and was graded (i.e. it was not anonymized).
Students had a week to submit the form, and could do so asynchronously.

All students submitted their scores for their first three attempts.
In this study, we will take their median response.

First, we only consider datapoints that have Stable Wifi (so we remove 2 points).
Moreover, to make sure we are not overfitting, we partition into 90% training and 10% testing.
Fitting models on the training set, we verify *a posteriori* whether the results are consistent on the testing set.
Finally, we conduct a differential study (fitting different models) on each category.

# Exploratory Data Analysis

```{r Libraries, echo = F, results='hide', error=F, warning=F, message=F}
library(knitr)
library(lmtest)
library(kableExtra)
library(tidyverse)
library(dplyr)
library(gridExtra)
library(MASS)
library(GGally)
library(leaps)
library(splines)
library(pls)
library(glmnet)
library(faraway)
library(psych)
library(ggcorrplot)
library(Metrics)
```

```{r Preprocessing1, echo = F, results = 'hide'}
survey <- read.csv("Survey.csv")

# filtering only Stable Wifi, on the Mouse and Trackpad conditions
data <- survey[survey$InputDevice %in% c("Mouse", "Trackpad"), ]
data <- data[data$WiFi == "Stable", ]

# processing the response variable to report Median Time
data$Time <- apply(data[, c("First", "Second", "Third")], 1, median)

# Organizing the levels as increasing severity
data$Stress <- factor(data$Stress, levels = c("Very Low", "Low", "Moderate", "High", "Very High"))
data$Fatigue <- factor(data$Fatigue, levels = c("Not fatigued at all", "Slightly Fatigued", "Moderately fatigued", "Very fatigued", "Extremely fatigued"), labels = c("Very Low", "Low", "Moderate", "High", "Very High"))

# Organizing it in ascending frequency
data$SportsPlay <- factor(data$SportsPlay, levels = c("Daily", "Several times a week", "Once a week", "Several times a month", "Rarely", "Never"))
data$VideoGamePlay <- factor(data$VideoGamePlay, levels = c("Daily", "Several times a week", "Once a week", "Several times a month", "Rarely", "Never"))

# Making them numeric
data$StressN <- as.numeric(data$Stress)
data$FatigueN <- as.numeric(data$Fatigue)
data$SportsPlayN <- as.numeric(data$SportsPlay)
data$VideoGamePlayN <- as.numeric(data$VideoGamePlay)

# Creating binary variable "High" and "Low"
data$ActiveSports <- data$SportsPlayN < 3
data$ActiveGame <- data$VideoGamePlayN < 3

# Creating binary variable for mouse or not
data$Mouse <- data$InputDevice == "Mouse"

# Correcting skewness in Exercise
data$LogExercise <- log(1 + data$AvgHoursExercise)
```

```{r Preprocessing2, echo = F, results = 'hide'}

# Partitioning into test and training datasets
data.test <- data[seq(10, nrow(data), by = 10), ]
data.train <- data[-seq(10, nrow(data), by = 10), ]
```

```{r tab1, echo = F, results = 'asis'}

data.train.mouse <- data.train[data.train$InputDevice == "Mouse", ]
data.train.track <- data.train[data.train$InputDevice == "Trackpad", ]

# Stress and Fatigue, on Mouse
t1a <- data.train.mouse %>% count(Fatigue)
t1b <- data.train.mouse %>% count(Stress)
t1 <- t1a %>% inner_join(t1b, by = c("Fatigue" = "Stress"))
colnames(t1) <- c("Level", "Fatigue", "Stress")
t1 <- t1 %>% add_row(Level = "Total", Fatigue = nrow(data.train.mouse), Stress = nrow(data.train.mouse))

# Stress and Fatigue, on Track
t3a <- data.train.track %>% count(Fatigue)
t3b <- data.train.track %>% count(Stress)
t3 <- t3a %>% inner_join(t3b, by = c("Fatigue" = "Stress"))
colnames(t3) <- c("Level", "Fatigue", "Stress")
t3 <- t3 %>% add_row(Level = "Total", Fatigue = nrow(data.train.track), Stress = nrow(data.train.track))

T1 <- t1 %>% inner_join(t3, by = "Level")
colnames(T1) <- c("Level", "FatigueMouse", "StressMouse", "FatigueTrack", "StressTrack")
knitr::kable(T1, align = "c", caption = "\\label{tabs:tab1}Fatigue and Stress counts on Training Dataset", booktabs = TRUE) %>%
    kableExtra::kable_styling(latex_options = "hold_position")
```

```{r tab2, echo = F, results = 'asis'}

# Game and Sports, on Mouse
t2a <- data.train.mouse %>% count(VideoGamePlay)
t2b <- data.train.mouse %>% count(SportsPlay)
t2 <- t2a %>% inner_join(t2b, by = c("VideoGamePlay" = "SportsPlay"))
colnames(t2) <- c("Level", "VideoGamePlay", "SportsPlay")
t2 <- t2 %>% add_row(Level = "Total", VideoGamePlay = nrow(data.train.mouse), SportsPlay = nrow(data.train.mouse))

# Game and Sports, on Track
t4a <- data.train.track %>% count(VideoGamePlay)
t4b <- data.train.track %>% count(SportsPlay)
t4 <- t4a %>% inner_join(t4b, by = c("VideoGamePlay" = "SportsPlay"))
colnames(t4) <- c("Level", "VideoGamePlay", "SportsPlay")
t4 <- t4 %>% add_row(Level = "Total", VideoGamePlay = nrow(data.train.track), SportsPlay = nrow(data.train.track))

T2 <- t2 %>% inner_join(t4, by = "Level")
colnames(T2) <- c("Level", "GameMouse", "SportsMouse", "GameTrack", "SportsTrack")

knitr::kable(T2, align = "c", caption = "\\label{tabs:tab2}Game and Sports counts on Training Dataset", booktabs = TRUE) %>%
    kableExtra::kable_styling(latex_options = "hold_position")
```

We see that there are very few datapoints for the *Very High* observations in our training dataset, and hence we remove these from the dataset (Table \ref{tabs:tab1}).
```{r, echo = F}
data.train <- data.train[data.train$Fatigue != "Very High", ]
data.train <- data.train[data.train$Stress != "Very High", ]
data.test <- data.test[data.test$Fatigue != "Very High", ]
data.test <- data.test[data.test$Stress != "Very High", ]
```

```{r fig1, fig.height = 3, echo = F, fig.cap="\\label{figs:fig1} Distribution of Response Variable on the Training Dataset. The x-axis describes the median response time in milliseconds. The y-axis describes the number of results."}
hist(data.train$Time, xlab = "Response Time (ms)", ylab = "Count", main = "")
```

We see that the response variable is roughly normally distributed across both mouse and trackpad groups (Figure \ref{figs:fig1}).

```{r tab3, echo = F}
df <- data.train[,c("Time", "StressN", "FatigueN", "NoiseLevel", "AvgHoursExercise", "AvgSleepTime", "LastNightSleep")]
tab3 <- round(as.matrix(describe(df))[, -c(1, 2)], 2)
knitr::kable(tab3, caption = "\\label{tabs:tab3} Descriptive Statistics", booktabs = TRUE) %>%
    kableExtra::kable_styling(latex_options = "hold_position")
```

```{r fig2a, fig.height = 3, echo = F, fig.cap="\\label{figs:fig2a} Transformed AvgHoursExercise"}
hist(data.train$LogExercise, xlab = "log(1 + AvgHoursExercise)", ylab = "Count", main = "")
```

From this table, we see that AvgHoursExercise is the only attribute that is heavily skewed (Table \ref{tabs:tab3}).
We try to correct this by applying a log transformation.
Indeed, after this, we correct most of the skew (Figure \ref{figs:fig2a}).

```{r fig2, fig.height = 3, echo = F, fig.cap="\\label{figs:fig2} Correlation Matrix"}
df <- data.train[, c("Time", "StressN", "FatigueN", "NoiseLevel", "LogExercise", "AvgSleepTime", "LastNightSleep")]
cor_heatmap <- cor(df)
ggcorrplot(cor_heatmap, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 1.4,
           colors = c("red", "white", "blue"),
           title = "Correlation Heatmap",
           ggtheme = theme_minimal())
```

Now, looking at the correlation heatmap, we see that there is lots of positive correlation between AvgSleep and LastNightSleep (Figure \ref{figs:fig2}).
Moreover, we see correlation between Fatigue and Stress, and also a negative correlation between LastNightSleep and Fatigue.
In general, there is little correlations within our data.

# Research Question One

We investigate separately on the Mouse and Trackpad users.

```{r, echo = F}
data.train.mouse <- data.train[data.train$InputDevice == "Mouse", ]
data.train.track <- data.train[data.train$InputDevice == "Trackpad", ]
```

## Mouse

```{r fig3, fig.height = 3, echo = F, fig.cap="\\label{figs:fig3} Median response time based on Fatigue and Stress levels. The y-axis shows the median response time across three trials. Left: Increasing Fatigue. Right: Increasing Stress."}
plot1 <- ggplot(data.train.mouse, aes(y = Fatigue, x = Time)) + geom_boxplot()
plot2 <- ggplot(data.train.mouse, aes(y = Stress, x = Time)) + geom_boxplot()
grid.arrange(plot1, plot2, ncol = 2)
```

```{r echo = F, results = 'hide'}
fit1 <- lm(StressN ~ Time, data = data.train.mouse)
fit2 <- lm(FatigueN ~ Time, data = data.train.mouse)
summary(fit1)   # p = 0.0342, R^2 = 0.0979
summary(fit2)   # p = 0.992,  R^2 = 0.0000
```

```{r echo = F, results = 'hide', fig.show = 'hide'}
## no outliers after Bonferroni correction

res <- rstudent(fit1)
crit <- qt(1 - 0.05 / (2 * nrow(data.train.mouse)), nrow(data.train.mouse) - 1)
plot(res)
abline(h = c(crit, -crit), col = "red")
```

```{r echo = F, results = 'hide', fig.show = 'hide'}
par(mfrow = c(2, 2))
plot(fit1, which = 1)  # Residuals vs Fitted
plot(fit1, which = 2)  # Q-Q plot
plot(fit1, which = 3)  # Scale-Location plot
plot(fit1, which = 4)  # Residuals vs Leverage

# Perform Shapiro-Wilk test
shapiro.test(resid(fit1)) # normality assumption seems violated
shapiro.test(resid(fit2)) # normality assumption seems violated

# Check for independence
bptest(fit1)
bptest(fit2)
```

Empirically, we see that for mouse users, the higher the aim training time level, the larger the stress.
Indeed, an increase of 200ms would lead to half a unit increase of stress level.
However, there seems to be no no clear trend for fatigue (Figure \ref{figs:fig3}).

There are no outliers, determined by studentized statistics ($\alpha = 0.05$, with Bonferroni correction).
We also tested for normality using the Shapiro-Wilks test. 
The residuals for both stress and fatigue SLR models seems non-normal (p < 0.05).
We tested for homoscedasticity using the B-P test.
The constant variance assumption held for both stress (p = 0.77) and fatigue (p = 0.74) SLR models.
All Cook's Distances were less than 1, so there are no highly influential points. 

## Trackpad

```{r fig4, fig.height = 3, echo = F, fig.cap="\\label{figs:fig4} Median response time based on Fatigue and Stress levels for Trackpad. The y-axis shows the median response time across three trials. Left: Increasing Fatigue. Right: Increasing Stress."}
plot1 <- ggplot(data.train.track, aes(y = Fatigue, x = Time)) + geom_boxplot()
plot2 <- ggplot(data.train.track, aes(y = Stress, x = Time)) + geom_boxplot()
grid.arrange(plot1, plot2, ncol = 2)
```

```{r echo = F, results = 'hide'}
fit1 <- lm(StressN ~ Time, data = data.train.track)
fit2 <- lm(FatigueN ~ Time, data = data.train.track)
summary(fit1)   # p = 0.0342, R^2 = 0.0979
summary(fit2)   # p = 0.992,  R^2 = 0.0000
```

```{r echo = F, results = 'hide', fig.show = 'hide'}
## no outliers after Bonferroni correction

res <- rstudent(fit1)
crit <- qt(1 - 0.05 / (2 * nrow(data.train.track)), nrow(data.train.track) - 1)
plot(res)
abline(h = c(crit, -crit), col = "red")
```

```{r echo = F, results = 'hide', fig.show = 'hide'}
par(mfrow = c(2, 2))
plot(fit1, which = 1)  # Residuals vs Fitted
plot(fit1, which = 2)  # Q-Q plot
plot(fit1, which = 3)  # Scale-Location plot
plot(fit1, which = 4)  # Residuals vs Leverage

# Perform Shapiro-Wilk test
shapiro.test(resid(fit1)) # normality assumption seems violated
shapiro.test(resid(fit2)) # normality assumption seems violated

# Check for independence
bptest(fit1)
bptest(fit2)
```

On the Trackpad condition, the trend is a lot less clear (Figure \ref{figs:fig4}).
Indeed, neither *Stress* nor *Fatigue* are significant predictors now (p > 0.05).

There are no outliers, determined by studentized statistics ($\alpha = 0.05$, with Bonferroni correction).
We also tested for normality using the Shapiro-Wilks test. 
The residuals for both stress and fatigue SLR models seems normal (p > 0.05).
We tested for homoscedasticity using the B-P test.
The constant variance assumption held for both stress (p = 0.64) and fatigue (p = 0.14) SLR models.
All Cook's Distances were less than 1, so there are no highly influential points. 

Trying several transformations did not improve the normality residuals assumption.
We leave it as is, since MLR is robust to violations of this.

# Research Question Two

Now, we try to determine if there are correlations between Stress and Fatigue, based on environmental factors such as *Distraction*, *NoiseLevel*.

```{r, echo = F, results = 'hide'}
fit3 <- lm(StressN ~ Distraction + NoiseLevel, data = data.train)
summary(fit3)
vif(fit3)
```

```{r, echo = F, results = 'hide'}
fit4 <- lm(FatigueN ~ Distraction + NoiseLevel, data = data.train)
summary(fit4)
vif(fit4)
```

Being in a highly distractive environment led to an increase in stress (p = 0.0126).
Environmental factors did not affect one's fatigue (p > 0.05).
There are no indicators nor evidence of any collinearity; in particular, all the VIF scores are low.

# Research Question Three

Now, let us now consider if there are correlations between Stress and Fatigue based on lifestyle habits, including sleep, exercise, sports, and gaming activity.

```{r, echo = F, results = 'hide'}
fit5 <- lm(StressN ~ LastNightSleep + LogExercise + ActiveSports + ActiveGame, data = data.train)
summary(fit5)
vif(fit5)
```

```{r, echo = F, results = 'hide'}
fit6 <- lm(FatigueN ~ LastNightSleep + LogExercise + ActiveSports + ActiveGame, data = data.train)
summary(fit6)
vif(fit6)
```

First, being active in sports decreases stress levels by half a unit (p = 0.084).
Indeed, this is the largest drop in stress levels out of any predictor.

Getting more sleep is also strongly related to decreases in fatigue (p = 0.00031).
Moreover, getting exercise is also strongly correlated with decreases in fatigue(p = 0.00668).

There are no indicators nor evidence of any collinearity; in particular, all the VIF scores are low.

# Model Building

We have studied three classes of predictors: aim training response time, lifestyle (Sports and Gaming), as well as environmental (Distraction).
It is clear that fatigue is only related to lifestyle habits, but it is unknown which of the classes of predictors are most important for stress.
Here, we synthesize the results and perform model comparison.

```{r echo = F, results = 'hide'}
fit <- lm(StressN ~ Time * Mouse + Distraction + NoiseLevel + ActiveSports + ActiveGame + LastNightSleep + LogExercise, data = data.train)
summary(fit)
anova(fit)
```

```{r echo = F, results = 'hide'}
stepwise_model <- step(fit, direction = "backward", k = 2)

fitStress <- lm(StressN ~ ActiveSports + Distraction, data = data.train)
summary(fitStress)
```

```{r echo = F, results = 'hide', fig.show = 'hide'}
## no outliers after Bonferroni correction

res <- rstudent(fitStress)
crit <- qt(1 - 0.05 / (2 * nrow(data.train)), nrow(data.train) - 1)
plot(res)
abline(h = c(crit, -crit), col = "red")
```

```{r echo = F, results = 'hide', fig.show = 'hide'}
par(mfrow = c(2, 2))
plot(fitStress, which = 1)  # Residuals vs Fitted
plot(fitStress, which = 2)  # Q-Q plot
plot(fitStress, which = 3)  # Scale-Location plot
plot(fitStress, which = 4)  # Residuals vs Leverage

# Perform Shapiro-Wilk test
shapiro.test(resid(fitStress)) # normality assumption seems violated

# Check for independence
bptest(fitStress)
```

```{r echo = F, results = 'hide'}
fit <- lm(FatigueN ~ Time * Mouse + Distraction + NoiseLevel + ActiveSports + ActiveGame + LastNightSleep + LogExercise, data = data.train)
summary(fit)
anova(fit)
```

```{r echo = F, results = 'hide'}
stepwise_model <- step(fit, direction = "backward", k = 2)

fitFatigue <- lm(FatigueN ~ LastNightSleep + Distraction + LogExercise + Time, data = data.train)
summary(fitFatigue)
```

```{r echo = F, results = 'hide', fig.show = 'hide'}
par(mfrow = c(2, 2))
plot(fitFatigue, which = 1)  # Residuals vs Fitted
plot(fitFatigue, which = 2)  # Q-Q plot
plot(fitFatigue, which = 3)  # Scale-Location plot
plot(fitFatigue, which = 4)  # Residuals vs Leverage

# Perform Shapiro-Wilk test
shapiro.test(resid(fitFatigue)) # normality assumption seems violated

# Check for independence
bptest(fitFatigue)
```

Running backwards variable selection using AIC, we find that we should use the predictors ActiveSports and Distraction to predict Stress.
Our final model, using predictors ActiveSports and Distraction, is
$$
    Stress \sim
    \begin{cases}
        2.463 & \text{if not active in sports and not distractive environment} \\
        2.018 & \text{if active in sports and not distractive environment} \\
        3.085 & \text{if not active in sports but distractive environment} \\
        2.640 & \text{if active in sports but distractive environment}
    \end{cases}
$$
Indeed, verifying all model assumptions, only the normality assumptions violated (p = 0.0023).
There are no outliers otherwise, and indeed no high leverage points.

Running backwards variable selection using AIC, we find that we should use the predictors LastNightSleep, Distraction, LogExercise, and ResponseTime to predict Fatigue. 
Our final model is
$$
    Fatigue \sim
    \begin{cases}
        4.739 - 0.149 * LastNightSleep - 0.301 * LogExercise - 0.0016 * Time & \text{If no distractions} \\
        5.039 - 0.149 * LastNightSleep - 0.301 * LogExercise - 0.0016 * Time & \text{If distractions} \\
    \end{cases}
$$
Moreover, we have no model violations (p > 0.05), including the normality assumption.

## Model Comparison

```{r echo = F, results = 'asis'}
fit1 <- lm(StressN ~ Time * Mouse, data = data.train)
fit2 <- lm(StressN ~ Distraction, data = data.train)
fit3 <- lm(StressN ~ ActiveSports, data = data.train)

aic <- t(as.data.frame(c(AIC(fitStress), AIC(fit1), AIC(fit2), AIC(fit3))))
rownames(aic) <- c("AIC")
colnames(aic) <- c("All", "AimTraining", "Environment", "Lifestyle")
knitr::kable(aic, align = "c", caption = "\\label{tabs:tab4}AIC scores for different Stress models", booktabs = TRUE) %>%
    kableExtra::kable_styling(latex_options = "hold_position")
```

```{r echo = F, results = 'asis'}
fit1 <- lm(FatigueN ~ 1, data = data.train)
fit2 <- lm(FatigueN ~ 1, data = data.train)
fit3 <- lm(FatigueN ~ LastNightSleep + LogExercise, data = data.train)

aic <- t(as.data.frame(c(AIC(fitFatigue), AIC(fit1), AIC(fit2), AIC(fit3))))
rownames(aic) <- c("AIC")
colnames(aic) <- c("All", "AimTraining", "Environment", "Lifestyle")
knitr::kable(aic, align = "c", caption = "\\label{tabs:tab5}AIC scores for different Fatigue models", booktabs = TRUE) %>%
    kableExtra::kable_styling(latex_options = "hold_position")
```

We can compare this aggregated model to the ones using predictors from each class individually.
Indeed, the aggregated model has the lowest AIC score for both the Stress and Fatigue models, and is the best (Tables \ref{tabs:tab4}, \ref{tabs:tab5}).

## a posteriori Validation

```{r echo = F, results = 'asis'}
predStress <- predict(fitStress, newdata = data.train)
predFatigue <- predict(fitFatigue, newdata = data.train)
e1 <- rmse(actual = data.train$StressN, predicted = predStress)
e2 <- rmse(actual = data.train$StressN, predicted = predFatigue)

predStress <- predict(fitStress, newdata = data.test)
predFatigue <- predict(fitFatigue, newdata = data.test)
e3 <- rmse(actual = data.test$StressN, predicted = predStress)
e4 <- rmse(actual = data.test$StressN, predicted = predFatigue)

errors <- t(as.data.frame(c(e1, e2, e3, e4)))
rownames(errors) <- c("RMSE")
colnames(errors) <- c("TrainStress", "TrainFatigue", "TestStress", "TestFatigue")
knitr::kable(errors, align = "c", caption = "\\label{tabs:tab6}RMSE between Training and Testing", booktabs = TRUE) %>%
    kableExtra::kable_styling(latex_options = "hold_position")
```

We evaluate the root mean squared error (RMSE) of the stress and fatigue models on the training and testing dataset.
We do not any inflated errors on the testing set, so we are probably not overfitting (Table \ref{tabs:tab6}).

# Discussion and Conclusion

Trying to predict stress and fatigue is difficult, and our models only explained around 10% of the variation for each.
However, we did gain valuable insights into which predictors are significant.

First, we determined that on trackpad, the aim training response time was too varied and there were no clear trends.
For future studies using aim training time as a predictor for mental state, we recommend to require mouse data in order to reduce the variation.
Indeed, for mouse users, we were able to say that the faster response times were correlated with decreased stress.

It was surprising that the level of noise in the environment was insignificant towards both stress and fatigue, since we expected more fatigue with noisy environments.
We verified that a highly distractive environment led to higher stress.
Unsurprisingly, fatigue levels are strongly correlated with one's lifestyle, namely their sports activity and sleep.

Finally, we verified that using all three classes of predictors lead to an improved model for both Fatigue and Stress.
Indeed, future studies should consider all not only response times, but also lifestyle, environmental factors before proposing remedies for Fatigue and Stress.

It is important to acknowledge that this study is inherently limited and only observational.
Moreover, because the responses was not anonymized, there may be biases towards the responses that would not otherwise be there.
Performing A/B testing is an important future step to see if the predictors we have determined to be significant are causal.
For example, it may be interesting to explore whether assigning students to work in distractive or non-distractive environments would lead to changes in stress and fatigue levels.

Moreover, in this study, we treated the categories for Fatigue and Stress as numerical (1-4), while in the study they were given as ordinal.
Perhaps further transformations of these responses would lead to improved analysis.
In addition, changing the study question to rate their Fatigue and Stress out of 10 may lead to it being more linear.
